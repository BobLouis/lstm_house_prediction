## 10. Advanced Result Visualization

### 10.1 Prediction Performance

```python
# Calculate different time windows for analysis
short_window = min(30, len(y_test_actual))
medium_window = min(90, len(y_test_actual))

# Create DataFrame for easier plotting
results_df = pd.DataFrame({
    'Actual': y_test_actual.flatten(),
    'Predicted': y_pred_actual.flatten(),
    'Error': (y_test_actual - y_pred_actual).flatten(),
    'Percent_Error': ((y_test_actual - y_pred_actual) / y_test_actual * 100).flatten()
})

# Plot full test set predictions
plt.figure(figsize=(14, 7))
plt.plot(results_df.index, results_df['Actual'], label='Actual Prices', linewidth=2)
plt.plot(results_df.index, results_df['Predicted'], label='Predicted Prices', linewidth=2, linestyle='--')
plt.fill_between(results_df.index, results_df['Actual'], results_df['Predicted'], alpha=0.3, color='lightgrey')
plt.title('House Price Prediction Results - Full Test Set', fontsize=16)
plt.xlabel('Test Sample Index', fontsize=12)
plt.ylabel('Price', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Plot short-term window for detailed view
plt.figure(figsize=(14, 7))
plt.plot(results_df.index[:short_window], results_df['Actual'][:short_window], 
         label='Actual', marker='o', markersize=6, linewidth=2)
plt.plot(results_df.index[:short_window], results_df['Predicted'][:short_window], 
         label='Predicted', marker='x', markersize=6, linewidth=2, linestyle='--')
plt.fill_between(results_df.index[:short_window], 
                results_df['Actual'][:short_window], 
                results_df['Predicted'][:short_window], 
                alpha=0.3, color='lightgrey')
plt.title(f'House Price Prediction - Detailed View (First {short_window} Samples)', fontsize=16)
plt.xlabel('Test Sample Index', fontsize=12)
plt.ylabel('Price', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Plot medium-term window
if len(y_test_actual) > 30:
    plt.figure(figsize=(14, 7))
    plt.plot(results_df.index[:medium_window], results_df['Actual'][:medium_window], 
             label='Actual', linewidth=2)
    plt.plot(results_df.index[:medium_window], results_df['Predicted'][:medium_window], 
             label='Predicted', linewidth=2, linestyle='--')
    plt.fill_between(results_df.index[:medium_window], 
                    results_df['Actual'][:medium_window], 
                    results_df['Predicted'][:medium_window], 
                    alpha=0.3, color='lightgrey')
    plt.title(f'House Price Prediction - Medium-term View (First {medium_window} Samples)', fontsize=16)
    plt.xlabel('Test Sample Index', fontsize=12)
    plt.ylabel('Price', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.show()
```

### 10.2 Error Analysis

```python
# Calculate cumulative metrics
cumulative_mae = np.abs(results_df['Error']).cumsum() / (results_df.index + 1)
cumulative_mape = np.abs(results_df['Percent_Error']).cumsum() / (results_df.index + 1)

# Plot cumulative MAE
plt.figure(figsize=(14, 7))
plt.plot(cumulative_mae, linewidth=2, color='darkblue')
plt.axhline(y=mae, color='r', linestyle='--', label=f'Overall MAE: {mae:.2f}')
plt.title('Cumulative Mean Absolute Error', fontsize=16)
plt.xlabel('Test Sample Index', fontsize=12)
plt.ylabel('Cumulative MAE', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Plot error distribution
plt.figure(figsize=(14, 7))
sns.histplot(results_df['Error'], kde=True, bins=30)
plt.axvline(x=0, color='r', linestyle='--', label='Zero Error')
plt.axvline(x=results_df['Error'].mean(), color='g', linestyle='-', 
            label=f'Mean Error: {results_df["Error"].mean():.2f}')
plt.title('Distribution of Prediction Errors', fontsize=16)
plt.xlabel('Prediction Error', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Plot percent error
plt.figure(figsize=(14, 7))
sns.histplot(results_df['Percent_Error'], kde=True, bins=30)
plt.axvline(x=0, color='r', linestyle='--', label='Zero Error')
plt.axvline(x=results_df['Percent_Error'].mean(), color='g', linestyle='-', 
            label=f'Mean Percent Error: {results_df["Percent_Error"].mean():.2f}%')
plt.title('Distribution of Percentage Errors', fontsize=16)
plt.xlabel('Percentage Error (%)', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()
```

### 10.3 Residual Analysis

```python
# Residual plots
plt.figure(figsize=(14, 7))
plt.scatter(results_df['Actual'], results_df['Error'], alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residual Plot (Error vs Actual Price)', fontsize=16)
plt.xlabel('Actual Price', fontsize=12)
plt.ylabel('Prediction Error', fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Residual vs predicted
plt.figure(figsize=(14, 7))
plt.scatter(results_df['Predicted'], results_df['Error'], alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residual Plot (Error vs Predicted Price)', fontsize=16)
plt.xlabel('Predicted Price', fontsize=12)
plt.ylabel('Prediction Error', fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# QQ plot of residuals
plt.figure(figsize=(14, 7))
sm.qqplot(results_df['Error'], line='s')
plt.title('Q-Q Plot of Residuals', fontsize=16)
plt.grid(True, alpha=0.3)
plt.show()
```

### 10.4 Prediction vs Actual Analysis

```python
# Enhanced scatter plot with regression line
plt.figure(figsize=(12, 10))
sns.regplot(x='Actual', y='Predicted', data=results_df, scatter_kws={'alpha':0.4}, line_kws={'color':'red'})
plt.plot([results_df['Actual'].min(), results_df['Actual'].max()], 
         [results_df['Actual'].min(), results_df['Actual'].max()], 
         'g--', linewidth=2)
plt.title('Actual vs Predicted Prices with Regression Line', fontsize=16)
plt.xlabel('Actual Price', fontsize=12)
plt.ylabel('Predicted Price', fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Calculate and display R-squared
from sklearn.metrics import r2_score
r2 = r2_score(results_df['Actual'], results_df['Predicted'])
print(f"R-squared (Coefficient of Determination): {r2:.4f}")
```

### 10.5 Performance by Price Range

```python
# Create price bins
num_bins = 5
results_df['Price_Bin'] = pd.qcut(results_df['Actual'], num_bins, labels=False)
bin_labels = [f'Bin {i+1}' for i in range(num_bins)]
bin_ranges = pd.qcut(results_df['Actual'], num_bins, retbins=True)[1]
bin_descriptions = [f"{bin_labels[i]} ({bin_ranges[i]:.0f}-{bin_ranges[i+1]:.0f})" for i in range(num_bins)]

# Calculate metrics per bin
bin_metrics = results_df.groupby('Price_Bin').agg(
    Mean_Actual=('Actual', 'mean'),
    Mean_Predicted=('Predicted', 'mean'),
    MAE=('Error', lambda x: np.mean(np.abs(x))),
    MAPE=('Percent_Error', lambda x: np.mean(np.abs(x))),
    Count=('Actual', 'count')
).reset_index()

# Plot MAE by price bin
plt.figure(figsize=(14, 7))
bars = plt.bar(bin_descriptions, bin_metrics['MAE'], color='skyblue')
plt.axhline(y=mae, color='r', linestyle='--', label=f'Overall MAE: {mae:.2f}')
plt.title('Mean Absolute Error by Price Range', fontsize=16)
plt.xlabel('Price Range', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3, axis='y')

# Add value labels on bars
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,
            f'{height:.1f}', ha='center', va='bottom')
plt.tight_layout()
plt.show()

# Plot MAPE by price bin
plt.figure(figsize=(14, 7))
bars = plt.bar(bin_descriptions, bin_metrics['MAPE'], color='lightgreen')
plt.axhline(y=mape, color='r', linestyle='--', label=f'Overall MAPE: {mape:.2f}%')
plt.title('Mean Absolute Percentage Error by Price Range', fontsize=16)
plt.xlabel('Price Range', fontsize=12)
plt.ylabel('MAPE (%)', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3, axis='y')

# Add value labels on bars
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,
            f'{height:.1f}%', ha='center', va='bottom')
plt.tight_layout()
plt.show()
```

### 10.6 Prediction Confidence Analysis

```python
# Generate multiple predictions by adding noise to input (Monte Carlo simulation)
num_simulations = 50
all_predictions = []

# Create a progress bar
from tqdm.notebook import tqdm

# Run multiple predictions with slight variations to input
for _ in tqdm(range(num_simulations)):
    # Add small random noise to test data (within Â±2% of original values)
    noise_factor = 0.02
    noisy_X_test = X_test + np.random.normal(0, noise_factor, X_test.shape)
    
    # Make predictions
    noisy_pred = model.predict(noisy_X_test)
    noisy_pred_actual = y_scaler.inverse_transform(noisy_pred)
    all_predictions.append(noisy_pred_actual.flatten())

# Convert to array
all_predictions = np.array(all_predictions)

# Calculate statistics
mean_predictions = np.mean(all_predictions, axis=0)
std_predictions = np.std(all_predictions, axis=0)
lower_bound = mean_predictions - 2 * std_predictions  # 95% confidence interval
upper_bound = mean_predictions + 2 * std_predictions

# Plot confidence intervals
plt.figure(figsize=(14, 7))
plt.plot(results_df.index[:100], results_df['Actual'][:100], 'b-', label='Actual', linewidth=2)
plt.plot(results_df.index[:100], mean_predictions[:100], 'r--', label='Mean Prediction', linewidth=2)
plt.fill_between(results_df.index[:100], 
                lower_bound[:100], 
                upper_bound[:100], 
                color='red', alpha=0.2, label='95% Confidence Interval')
plt.title('House Price Predictions with Confidence Intervals (First 100 Samples)', fontsize=16)
plt.xlabel('Test Sample Index', fontsize=12)
plt.ylabel('Price', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Calculate and display confidence interval width statistics
ci_width = upper_bound - lower_bound
print(f"Average 95% Confidence Interval Width: {np.mean(ci_width):.2f}")
print(f"Min CI Width: {np.min(ci_width):.2f}, Max CI Width: {np.max(ci_width):.2f}")
print(f"CI Width as % of Predicted Price: {np.mean(ci_width/mean_predictions*100):.2f}%")
```

### 10.7 Long-Term Forecast Visualization

```python
# Function to generate multi-step ahead forecasts
def forecast_future(start_sequence, n_steps, model, X_scaler, y_scaler, feature_dim):
    """
    Generate multi-step ahead forecasts
    
    Args:
        start_sequence: Initial sequence to start forecasting from
        n_steps: Number of steps to forecast
        model: Trained LSTM model
        X_scaler, y_scaler: Scalers for features and target
        feature_dim: Number of features
        
    Returns:
        Array of forecasted values
    """
    # Make a copy of the starting sequence
    curr_sequence = start_sequence.copy()
    forecast = []
    
    # Generate forecasts step by step
    for _ in range(n_steps):
        # Reshape for prediction
        X_pred = curr_sequence.reshape(1, curr_sequence.shape[0], curr_sequence.shape[1])
        
        # Get prediction (scaled)
        y_pred_scaled = model.predict(X_pred)[0]
        forecast.append(y_pred_scaled[0])
        
        # Create a new feature vector by using current feature values
        # In a real application, you would need to provide values for other features
        new_features = np.zeros(feature_dim)
        new_features[0] = y_pred_scaled[0]  # Set price feature
        
        # Update sequence by removing first step and adding new prediction
        curr_sequence = np.vstack([curr_sequence[1:], new_features])
    
    # Convert forecasts to original scale
    forecast_array = np.array(forecast).reshape(-1, 1)
    forecast_rescaled = y_scaler.inverse_transform(forecast_array)
    
    return forecast_rescaled.flatten()

# Get the last sequence from training data
last_sequence = X_train[-1]
feature_dim = X_train.shape[2]

# Generate future forecasts for 24 steps
forecast_horizon = min(24, len(y_test_actual))
future_forecast = forecast_future(last_sequence, forecast_horizon, model, X_scaler, y_scaler, feature_dim)

# Plot long-term forecast
plt.figure(figsize=(14, 7))

# Plot actual test data
plt.plot(np.arange(len(y_test_actual[:forecast_horizon])), 
         y_test_actual[:forecast_horizon].flatten(), 
         'b-', linewidth=2, label='Actual Test Data')

# Plot forecasted data
plt.plot(np.arange(len(future_forecast)), 
         future_forecast, 
         'g--', linewidth=2, label='Long-term Forecast')

# Plot one-step-ahead predictions for comparison
plt.plot(np.arange(len(y_pred_actual[:forecast_horizon])), 
         y_pred_actual[:forecast_horizon].flatten(), 
         'r:', linewidth=2, label='One-step-ahead Predictions')

plt.title('Long-term Forecasting vs One-step-ahead Predictions', fontsize=16)
plt.xlabel('Steps Ahead', fontsize=12)
plt.ylabel('Price', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()
```

### 10.8 Feature Correlation Matrix Heatmap

```python
# Import required for this section
import statsmodels.api as sm

# Add index time information to results dataframe
if 'Date' in df.columns:
    # Map dates to test set indices (this is approximate as test set might not be continuous)
    test_dates = df.sort_values('Date')['Date'].iloc[-len(y_test_actual):].values
    results_df['Date'] = test_dates
    
    # Plot predictions over time
    plt.figure(figsize=(14, 7))
    plt.plot(results_df['Date'], results_df['Actual'], label='Actual', linewidth=2)
    plt.plot(results_df['Date'], results_df['Predicted'], label='Predicted', linewidth=2, linestyle='--')
    plt.title('House Price Predictions Over Time', fontsize=16)
    plt.xlabel('Date', fontsize=12)
    plt.ylabel('Price', fontsize=12)
    plt.legend(fontsize=12)
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

# Create correlation matrix heatmap for all numeric features vs target
correlation_data = df.select_dtypes(include=['number'])
correlation_matrix = correlation_data.corr()

# Create mask for upper triangle
mask = np.triu(correlation_matrix)

# Plot correlation heatmap
plt.figure(figsize=(16, 14))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
            mask=mask, linewidths=0.5, vmin=-1, vmax=1, center=0)
plt.title('Feature Correlation Matrix Heatmap', fontsize=16)
plt.tight_layout()
plt.show()

# Plot correlation with target specifically
target_correlations = correlation_matrix['TotalPrice'].drop('TotalPrice').sort_values(ascending=False)
plt.figure(figsize=(14, 10))
bars = plt.barh(target_correlations.index, target_correlations.values, color='skyblue')
plt.axvline(x=0, color='gray', linestyle='--')
plt.title('Feature Correlation with House Price', fontsize=16)
plt.xlabel('Correlation Coefficient', fontsize=12)
plt.ylabel('Feature', fontsize=12)
plt.grid(True, alpha=0.3, axis='x')
plt.xlim(-1, 1)

# Add value labels on bars
for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.01 if width >= 0 else width - 0.07, 
            bar.get_y() + bar.get_height()/2., 
            f'{width:.2f}', 
            ha='left' if width >= 0 else 'right', 
            va='center')
            
plt.tight_layout()
plt.show()
```

Note: When adding these sections to your notebook, please remember to add the following import at the beginning of the notebook if not already present:
```python
import statsmodels.api as sm
from tqdm.notebook import tqdm
```
